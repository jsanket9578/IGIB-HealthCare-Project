{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "comp_path = os.path.normpath(pathlib.Path().absolute())+os.path.normpath(\"/challengeLab-ML/data/train/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '/challengeLab-ML/data/'\n",
      "C:\\Users\\Lenovo\\Desktop\\Plaksha Course Material\\Healthcare\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['immunome.csv',\n",
       " 'SerumLuminex.csv',\n",
       " 'plasmaLuminex.csv',\n",
       " 'plasmaSomalogic.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub_cl1_file_names = \"immunome,SerumLuminex,plasmaLuminex,plasmaSomalogic\".split(\",\")\n",
    "sub_cl1_file_names = [x+\".csv\" for x in sub_cl1_file_names]\n",
    "sub_cl1_file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immunome = pd.read_csv(os.path.join(comp_path,sub_cl1_file_names[0])) #68*535\n",
    "df_immunome[\"SampleID\"].unique().shape  #File has unique SampleID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(pd.isna(df_immunome))\n",
    "#No Null values in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immunome.dtypes[1:].unique() #All columns float except the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd \"challengeLab-ML/data/\"\n",
    "targets_df = pd.read_csv(\"challenge-meta-information.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df[\"randPerson\"].unique().shape\n",
    "#Total 17 women, each observed 4 times\n",
    "\n",
    "targets_df = targets_df[[\"GA\",\"SampleID\",\"data\"]]\n",
    "\n",
    "df_immunome = pd.merge(df_immunome,targets_df,on=\"SampleID\",).iloc[:,1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immunome_train = df_immunome[df_immunome[:,-1]==\"train\"][:,:-1] \n",
    "df_immunome_test = df_immunome[df_immunome[:,-1]==\"test\"][:,:-1]\n",
    "#536 features, 1 label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_transf = MinMaxScaler()\n",
    "X_train = scaling_transf.fit_transform(df_immunome_train[:,:-1])\n",
    "X_test = scaling_transf.transform(df_immunome_test[:,:-1])\n",
    "\n",
    "y_train = df_immunome_train[:,-1]\n",
    "y_test = df_immunome_test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#using MAE - quantile regression\n",
    "regressor = SGDRegressor(loss=\"epsilon_insensitive\",epsilon=0,penalty=\"l1\",alpha=0.001,max_iter=100,eta0=0.01,power_t=0.25,learning_rate=\"invscaling\",n_iter_no_change=7,verbose=1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.09, NNZs: 534, Bias: 0.097670, T: 56, Avg. loss: 9.768747\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.09, NNZs: 533, Bias: 0.098060, T: 112, Avg. loss: 8.484667\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.22, NNZs: 534, Bias: 0.109594, T: 168, Avg. loss: 8.380808\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.26, NNZs: 533, Bias: 0.109764, T: 224, Avg. loss: 8.229763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.43, NNZs: 533, Bias: 0.124236, T: 280, Avg. loss: 8.060503\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.40, NNZs: 533, Bias: 0.119353, T: 336, Avg. loss: 8.103372\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.51, NNZs: 531, Bias: 0.128221, T: 392, Avg. loss: 7.889000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.50, NNZs: 528, Bias: 0.123841, T: 448, Avg. loss: 7.874791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.53, NNZs: 527, Bias: 0.123798, T: 504, Avg. loss: 7.864231\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.68, NNZs: 526, Bias: 0.136052, T: 560, Avg. loss: 7.674586\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.68, NNZs: 524, Bias: 0.131969, T: 616, Avg. loss: 7.755417\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.72, NNZs: 519, Bias: 0.131896, T: 672, Avg. loss: 7.636726\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.73, NNZs: 519, Bias: 0.128050, T: 728, Avg. loss: 7.583333\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.86, NNZs: 525, Bias: 0.139358, T: 784, Avg. loss: 7.466106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.92, NNZs: 522, Bias: 0.143044, T: 840, Avg. loss: 7.474251\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.89, NNZs: 519, Bias: 0.132036, T: 896, Avg. loss: 7.419896\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.03, NNZs: 521, Bias: 0.146463, T: 952, Avg. loss: 7.377666\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.06, NNZs: 515, Bias: 0.146410, T: 1008, Avg. loss: 7.373198\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 2.10, NNZs: 517, Bias: 0.146356, T: 1064, Avg. loss: 7.334581\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 2.14, NNZs: 518, Bias: 0.146366, T: 1120, Avg. loss: 7.292733\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 2.24, NNZs: 519, Bias: 0.156612, T: 1176, Avg. loss: 7.187416\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 2.22, NNZs: 521, Bias: 0.146417, T: 1232, Avg. loss: 7.053781\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.30, NNZs: 519, Bias: 0.153122, T: 1288, Avg. loss: 7.148346\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.40, NNZs: 520, Bias: 0.162987, T: 1344, Avg. loss: 7.032016\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.39, NNZs: 518, Bias: 0.156408, T: 1400, Avg. loss: 7.109864\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2.44, NNZs: 520, Bias: 0.156429, T: 1456, Avg. loss: 7.041227\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.47, NNZs: 516, Bias: 0.156445, T: 1512, Avg. loss: 7.006156\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2.54, NNZs: 515, Bias: 0.162814, T: 1568, Avg. loss: 6.931028\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2.61, NNZs: 519, Bias: 0.169108, T: 1624, Avg. loss: 6.849813\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2.65, NNZs: 512, Bias: 0.169063, T: 1680, Avg. loss: 6.921944\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2.66, NNZs: 503, Bias: 0.165922, T: 1736, Avg. loss: 6.870548\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2.70, NNZs: 499, Bias: 0.165938, T: 1792, Avg. loss: 6.838613\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2.74, NNZs: 504, Bias: 0.165955, T: 1848, Avg. loss: 6.788416\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2.79, NNZs: 503, Bias: 0.169006, T: 1904, Avg. loss: 6.780728\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2.87, NNZs: 505, Bias: 0.178000, T: 1960, Avg. loss: 6.651215\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2.93, NNZs: 504, Bias: 0.183942, T: 2016, Avg. loss: 6.654016\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2.92, NNZs: 504, Bias: 0.175025, T: 2072, Avg. loss: 6.749601\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2.96, NNZs: 512, Bias: 0.175022, T: 2128, Avg. loss: 6.642674\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3.01, NNZs: 506, Bias: 0.180885, T: 2184, Avg. loss: 6.605823\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3.03, NNZs: 513, Bias: 0.175062, T: 2240, Avg. loss: 6.549141\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3.10, NNZs: 510, Bias: 0.183748, T: 2296, Avg. loss: 6.571561\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3.15, NNZs: 509, Bias: 0.186602, T: 2352, Avg. loss: 6.502907\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3.17, NNZs: 514, Bias: 0.183744, T: 2408, Avg. loss: 6.535012\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3.21, NNZs: 514, Bias: 0.183750, T: 2464, Avg. loss: 6.497837\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3.28, NNZs: 512, Bias: 0.192207, T: 2520, Avg. loss: 6.396871\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3.31, NNZs: 514, Bias: 0.192191, T: 2576, Avg. loss: 6.425039\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3.32, NNZs: 515, Bias: 0.186611, T: 2632, Avg. loss: 6.392594\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3.38, NNZs: 514, Bias: 0.192177, T: 2688, Avg. loss: 6.385927\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3.44, NNZs: 516, Bias: 0.197695, T: 2744, Avg. loss: 6.328445\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3.46, NNZs: 513, Bias: 0.194932, T: 2800, Avg. loss: 6.367207\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3.49, NNZs: 508, Bias: 0.194928, T: 2856, Avg. loss: 6.326217\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3.51, NNZs: 509, Bias: 0.192215, T: 2912, Avg. loss: 6.277880\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3.58, NNZs: 508, Bias: 0.200354, T: 2968, Avg. loss: 6.278453\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3.61, NNZs: 508, Bias: 0.200336, T: 3024, Avg. loss: 6.255778\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3.66, NNZs: 508, Bias: 0.205696, T: 3080, Avg. loss: 6.199339\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3.69, NNZs: 505, Bias: 0.205683, T: 3136, Avg. loss: 6.225866\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3.71, NNZs: 510, Bias: 0.200359, T: 3192, Avg. loss: 6.131623\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3.74, NNZs: 510, Bias: 0.203023, T: 3248, Avg. loss: 6.165965\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3.80, NNZs: 509, Bias: 0.208297, T: 3304, Avg. loss: 6.125860\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3.85, NNZs: 507, Bias: 0.213528, T: 3360, Avg. loss: 6.041901\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3.84, NNZs: 509, Bias: 0.203049, T: 3416, Avg. loss: 6.047217\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3.88, NNZs: 508, Bias: 0.205677, T: 3472, Avg. loss: 6.087101\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3.94, NNZs: 505, Bias: 0.216061, T: 3528, Avg. loss: 6.014021\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3.97, NNZs: 509, Bias: 0.213467, T: 3584, Avg. loss: 6.051583\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.02, NNZs: 507, Bias: 0.218607, T: 3640, Avg. loss: 5.934291\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.04, NNZs: 504, Bias: 0.216024, T: 3696, Avg. loss: 6.009576\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.07, NNZs: 505, Bias: 0.216020, T: 3752, Avg. loss: 5.978582\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.08, NNZs: 510, Bias: 0.210933, T: 3808, Avg. loss: 5.900943\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.12, NNZs: 506, Bias: 0.216023, T: 3864, Avg. loss: 5.943652\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.18, NNZs: 502, Bias: 0.226130, T: 3920, Avg. loss: 5.815586\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.18, NNZs: 503, Bias: 0.218562, T: 3976, Avg. loss: 5.937907\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 4.22, NNZs: 501, Bias: 0.223576, T: 4032, Avg. loss: 5.832106\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 4.24, NNZs: 504, Bias: 0.221061, T: 4088, Avg. loss: 5.861316\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 4.28, NNZs: 502, Bias: 0.223550, T: 4144, Avg. loss: 5.850365\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 4.29, NNZs: 506, Bias: 0.221059, T: 4200, Avg. loss: 5.793171\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 4.31, NNZs: 510, Bias: 0.218593, T: 4256, Avg. loss: 5.815412\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 4.35, NNZs: 501, Bias: 0.225993, T: 4312, Avg. loss: 5.793647\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 4.37, NNZs: 507, Bias: 0.223531, T: 4368, Avg. loss: 5.798214\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 4.40, NNZs: 506, Bias: 0.225976, T: 4424, Avg. loss: 5.779061\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 4.42, NNZs: 508, Bias: 0.225967, T: 4480, Avg. loss: 5.775146\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 4.45, NNZs: 505, Bias: 0.228403, T: 4536, Avg. loss: 5.749042\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 4.46, NNZs: 506, Bias: 0.223535, T: 4592, Avg. loss: 5.697862\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 4.48, NNZs: 507, Bias: 0.223544, T: 4648, Avg. loss: 5.714991\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 4.53, NNZs: 501, Bias: 0.235610, T: 4704, Avg. loss: 5.570140\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 4.53, NNZs: 504, Bias: 0.228371, T: 4760, Avg. loss: 5.731904\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 4.54, NNZs: 504, Bias: 0.225970, T: 4816, Avg. loss: 5.698098\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 4.57, NNZs: 504, Bias: 0.225972, T: 4872, Avg. loss: 5.681923\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 4.59, NNZs: 505, Bias: 0.228366, T: 4928, Avg. loss: 5.667604\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 4.62, NNZs: 504, Bias: 0.230739, T: 4984, Avg. loss: 5.636563\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 4.65, NNZs: 505, Bias: 0.233104, T: 5040, Avg. loss: 5.620672\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 4.68, NNZs: 504, Bias: 0.235457, T: 5096, Avg. loss: 5.603160\n",
      "Total training time: 0.18 seconds.\n",
      "Convergence after 91 epochs took 0.18 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.001, average=False, early_stopping=False, epsilon=0,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
       "             max_iter=100, n_iter_no_change=7, penalty='l1', power_t=0.25,\n",
       "             random_state=None, shuffle=True, tol=0.001,\n",
       "             validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.561594365585848"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=regressor.predict(X_test)\n",
    "mean_absolute_error(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
